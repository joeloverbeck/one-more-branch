# Prompt Engineering Strategies

We recently derived the files in prompts/* (and subdirectories) from the actual prompts that are built in this app. I fed them to ChatGPT's deep research to determine how we should improve them according to actual research on LLMs.

## Strengthen Schema Guidance with Structured Prompts

When prompting for structured outputs like JSON story nodes, provide explicit schema instructions and use labeled sections. Claude 4.5 especially benefits from well-structured prompts – it was trained on tagged formats (XML/JSON) and parses them effectively. Define each JSON field with clear descriptions or even example patterns to guide the model. For instance, you might specify that a "goal" field must start with "To ..." and a "decision" field should be phrased as "{character} decides to ...". In practice, researchers include inline comments or schemas in the prompt illustrating the exact JSON shape and content constraints. This robust schema guidance ensures the model knows how to format the output and what each part means, reducing formatting errors and omissions. It also helps control output length and structure – for example, using a fixed schema to enforce a set number of events or choices. In sum, be explicit about the JSON structure: enumerate required fields, allowed values or styles, and the relationship between fields (e.g. that each choice is an object with a "text" property). Such structured prompts yield much more consistent, valid JSON from the model.

## Provide Few-Shot Examples and Role Instructions

Illustrate the desired output and narrative style through examples. Few-shot prompting (including 1–3 examples of high-quality story snippets with choices) can significantly improve fidelity and formatting by giving the model a pattern to imitate. For instance, you might show a mini passage:

{
  "text": "You stand at a crossroads in the dark forest, the moon your only light. The air is thick with the scent of pine and danger.",  
  "choices": [
    {"text": "Venture down the left path, toward the old cabin."},
    {"text": "Take the right path, deeper into the shadowy woods."}
  ]
}


Follow this with the real prompt for the next story segment. By seeing a concrete demonstration, the model learns the desired JSON structure, tone, and level of detail. Make sure your examples reflect tone consistency and character voice as well – the model will pick up those cues. In addition, use role or persona instructions to set the narrative voice. For example, a system prompt might say “You are a skilled storytelling AI who writes in a suspenseful, second-person perspective while maintaining the protagonist’s established personality.” In a similar vein, one interactive fiction system’s prompt defined the narrator’s role and perspective explicitly (second-person, never naming the protagonist) to keep output on track. Defining the AI’s role (e.g. “helpful fiction writer assistant”) and giving it a few concrete examples to follow will anchor the style and format, yielding more consistent tone and higher-quality narrative flow.

## Use Chain-of-Thought and Stepwise Planning

Complex storytelling tasks benefit from giving the model “space to think” before finalizing output. Chain-of-thought prompting involves instructing the LLM to reason through the narrative and choices step-by-step internally. One effective technique is to embed a hidden reasoning phase in the prompt using special tokens or sections, then have the model produce the final story JSON separately. For example, you can prompt Claude with a structure like:

<thinking>Plan the next scene and possible player decisions based on the current situation, ensuring logical consistency and interesting alternatives.</thinking> 
<output>JSON_SCHEMA_HERE</output>


Anthropic’s guidance suggests using tags (e.g. <thinking>...</thinking>) to let Claude generate a detailed internal plan which you strip out, so the model truly does the reasoning work off-screen. This might include the model silently outlining the scene’s key events, checking the character’s motivations, and formulating 2-3 plausible divergent choices. After this internal “brainstorm,” the model then outputs only the final JSON with the narrative and choices (perhaps under an <output> tag). Critically, the chain-of-thought must be actually generated in the prompt – Claude won’t fully reason through steps unless it’s allowed to output them in some form. By separating reasoning from the answer, you get more coherent, well-structured storytelling. Developers in interactive fiction have noted that LLMs tell much better stories if they first draft or outline the next events and then continue with the narrative, just as a human game master would plan ahead. You can implement this by either multi-turn prompts (first ask for an outline, then feed it back) or a single prompt with a clearly demarcated “think then continue” section. The result is improved plot coherence and fewer contradictions, at the cost of some extra tokens and latency. If latency is a concern, use this technique for particularly complex junctures (e.g. big plot twists) rather than every single turn. Overall, guiding the model through a brief planning phase encourages it to maintain narrative consistency and avoid plot holes before committing words to the page.

## Specify Narrative Quality and Tone Requirements

Don’t assume the model will infer the desired narrative style – spell it out. Claude 4.5 is very literal in following instructions, so you should explicitly describe the quality bar and tonal goals for the story. For example, if you want a cinematic, immersive style, say so: “Write vivid, sensory descriptions that ‘show, not tell’ the scene. Maintain a haunting, melancholic tone throughout. Keep the voice consistent with the earlier chapters (e.g. the protagonist’s narration remains wry and informal).” Provide guidelines on perspective (first/second/third person), tense, and any stylistic devices it should or shouldn’t use. Being “brutally specific” about these requirements helps Claude go beyond generic prose. You can even motivate the instructions with reasoning, as Claude tends to generalize rules better if given a rationale. For instance: “The story should avoid abrupt tone shifts or out-of-character humor, because consistency keeps the player immersed and maintains believability.” Such context helps the model apply style rules even in edge cases. In practice, high-end interactive fiction prompts often include a section of writing tips or rules – essentially a miniature style guide – covering tone, pacing, dialogue style, etc., to steer the model. By front-loading these narrative goals and constraints, you maximize the chance that the AI’s output stays on target: richly written, consistent in voice, and within desired content and quality parameters.

## Craft Realistic and Divergent Player Choices

To maximize player engagement, each choice should feel plausible and consequential. Prompt the model with instructions to generate distinct, meaningful options rather than shallow or repetitive ones. One proven strategy is to have the prompt remind the model of the protagonist’s current state and goal in the story, and base choices on that context. For example: “Given the hero is injured and desperate to escape (state: injured captive; goal: to survive and flee), propose two decisions the hero might genuinely consider in this moment.” This approach, used in recent research, guards against illogical branches. It prevents the AI from offering “non-choices” or impossible actions that the character would never undertake (e.g. a prisoner deciding to be ambushed – which isn’t a choice at all). It also avoids out-of-character choices – like a brave protagonist suddenly fleeing without reason – by grounding options in the character’s established motivations and personality. Additionally, instruct the model to avoid trivial or stagnating choices that don’t move the story forward. For instance, a “do nothing” option or an immediate retreat might be realistic in some scenarios, but often they lead to uninteresting dead-ends. Encourage choices that each lead to different outcomes or story branches (the more divergent, the better, as long as all remain plausible). You can explicitly say: “Each choice should result in a significantly different storyline. Ensure the options are mutually exclusive and cover a range of approaches (e.g. a cautious plan vs. a bold risk).” To help the model, it can be useful to include in the prompt a brief reminder of past branches to avoid repetition – e.g. “Previously, the player chose to fight. Now one option could be nonviolent to explore an alternative path.” Some advanced prompts even have the model imagine consequences for each decision internally before writing them out, ensuring the choices indeed diverge and have weight. By clearly delineating what makes a good choice (believable for the character, growing from the situation, and leading the plot in new directions), your prompt will guide Claude to produce options that feel real and interesting to the player.

## Leverage Claude 4.5’s Strengths with Tailored Adjustments

Finally, keep in mind specific techniques that work best with Claude 4.5 (Sonnet). As noted, this model is less likely to “fill in the blanks” itself – you must ask for everything you want. The upside is that if you craft very explicit, structured prompts, Claude will follow them diligently. Take advantage of that: use the structured prompt sections for context, style, schema, and examples as discussed, since Claude was effectively trained on such formatted instructions. Also, don’t hesitate to literally enumerate requirements (e.g. “1. Do X, 2. Do Y, 3. Output Z”) within the prompt. Breaking the task into an ordered list of sub-tasks can help Sonnet models systematically satisfy each part. If you find the model still deviates or forgets an element (for example, occasionally returning only one choice when you asked for two), reinforce the instruction by placing it in a prominent way (such as in the schema or as a bolded “Must have 2 choices” line). The research on Claude 4.x shows that being overly clear and even redundant with important instructions yields more reliable results. Another Claude-specific tip is to utilize its high token context: you can supply ample story history or an outline of previous plot points in the prompt to help maintain consistency. Claude can handle very long prompts, so include a running summary of key events or character traits as the story progresses. This acts like memory, reducing the chance of contradictions or tone drift. In summary, mold the prompt to Claude’s “literal-minded” nature: structure it, give examples, articulate every rule (with reasons when appropriate), and ask for exactly what you need in the output. By doing so, you’ll harness Claude 4.5’s strengths to produce interactive fiction that boasts high narrative quality, consistent tone, and realistic, compelling branching choices.

## Sources

Recent interactive fiction research and Anthropic Claude documentation have informed these recommendations, along with community insights from AI-driven storytelling projects. These sources emphasize that thoughtful prompt design – from schema detailing to example-driven guidance and chain-of-thought planning – is key to guiding large language models in generating rich, coherent branching narratives.

